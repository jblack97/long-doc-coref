{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from os import path\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"large\"\n",
    "tf_checkpoint = f'/home/shtoshni/Research/mandar_coref/coref/data/spanbert_{model_size}/model.max.ckpt'\n",
    "output_dir = '/home/shtoshni/Research/litbank_coref/resources/mentions'\n",
    "if not path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "antecedent_distance_emb [10, 20]\n",
      "coref_layer/antecedent_distance_emb [10, 20]\n",
      "coref_layer/f/output_bias [3092]\n",
      "coref_layer/f/output_weights [6184, 3092]\n",
      "coref_layer/same_speaker_emb [2, 20]\n",
      "coref_layer/segment_distance/segment_distance_embeddings [3, 20]\n",
      "coref_layer/slow_antecedent_scores/hidden_bias_0 [3000]\n",
      "coref_layer/slow_antecedent_scores/hidden_weights_0 [9356, 3000]\n",
      "coref_layer/slow_antecedent_scores/output_bias [1]\n",
      "coref_layer/slow_antecedent_scores/output_weights [3000, 1]\n",
      "genre_embeddings [7, 20]\n",
      "mention_scores/hidden_bias_0 [3000]\n",
      "mention_scores/hidden_weights_0 [3092, 3000]\n",
      "mention_scores/output_bias [1]\n",
      "mention_scores/output_weights [3000, 1]\n",
      "mention_word_attn/output_bias [1]\n",
      "mention_word_attn/output_weights [1024, 1]\n",
      "output_bias [1]\n",
      "output_weights [20, 1]\n",
      "span_width_embeddings [30, 20]\n",
      "span_width_prior_embeddings [30, 20]\n",
      "src_projection/output_bias [3092]\n",
      "src_projection/output_weights [3092, 3092]\n",
      "width_scores/hidden_bias_0 [3000]\n",
      "width_scores/hidden_weights_0 [20, 3000]\n",
      "width_scores/output_bias [1]\n",
      "width_scores/output_weights [3000, 1]\n"
     ]
    }
   ],
   "source": [
    "model_vars = tf.train.list_variables(tf_checkpoint)\n",
    "\n",
    "for name, shape in model_vars:\n",
    "    if 'bert' in name or 'Adam' in name or 'beta' in name or 'global_step' in name:\n",
    "        continue\n",
    "    print(name, shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mention vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mention_scores/hidden_bias_0 [3000]\n",
      "mention_scores/hidden_weights_0 [3092, 3000]\n",
      "mention_scores/output_bias [1]\n",
      "mention_scores/output_weights [3000, 1]\n",
      "mention_word_attn/output_bias [1]\n",
      "mention_word_attn/output_weights [1024, 1]\n",
      "span_width_embeddings [30, 20]\n",
      "span_width_prior_embeddings [30, 20]\n",
      "width_scores/hidden_bias_0 [3000]\n",
      "width_scores/hidden_weights_0 [20, 3000]\n",
      "width_scores/output_bias [1]\n",
      "width_scores/output_weights [3000, 1]\n"
     ]
    }
   ],
   "source": [
    "for name, shape in model_vars:\n",
    "    if 'bert' in name or 'Adam' in name:\n",
    "        continue\n",
    "    if 'mention' in name or 'width' in name:\n",
    "        print(name, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mention_mlp.fc_layers.0.weight torch.Size([3000, 3092])\n",
      "mention_mlp.fc_layers.1.weight torch.Size([1, 3000])\n",
      "mention_attn.weight torch.Size([1, 1024])\n",
      "span_width_mlp.fc_layers.0.weight torch.Size([3000, 20])\n",
      "span_width_mlp.fc_layers.1.weight torch.Size([1, 3000])\n",
      "mention_scores/hidden_weights_0 2068\n",
      "mention_mlp.fc_layers.0.weight torch.Size([3000, 2068])\n",
      "mention_mlp.fc_layers.1.weight torch.Size([1, 3000])\n",
      "mention_attn.weight torch.Size([1, 1024])\n",
      "span_width_mlp.fc_layers.0.weight torch.Size([3000, 20])\n",
      "span_width_mlp.fc_layers.1.weight torch.Size([1, 3000])\n"
     ]
    }
   ],
   "source": [
    "for ment_emb in ['attn', 'endpoint']:\n",
    "    pytorch_dump_path = path.join(output_dir, f'mention_ontonotes_{model_size}_{ment_emb}.pt')\n",
    "    model_state_dict = OrderedDict()\n",
    "    \n",
    "    tf_var_to_torch_var = OrderedDict()\n",
    "\n",
    "    tf_var_to_torch_var['mention_scores/hidden_weights_0'] = 'mention_mlp.fc_layers.0.weight'\n",
    "    tf_var_to_torch_var['mention_scores/hidden_bias_0'] = 'mention_mlp.fc_layers.0.bias'\n",
    "    tf_var_to_torch_var['mention_scores/output_weights'] = 'mention_mlp.fc_layers.1.weight'\n",
    "    tf_var_to_torch_var['mention_scores/output_bias'] = 'mention_mlp.fc_layers.1.bias'\n",
    "    tf_var_to_torch_var['mention_word_attn/output_weights'] = 'mention_attn.weight'\n",
    "    tf_var_to_torch_var['mention_word_attn/output_bias'] = 'mention_attn.bias'\n",
    "\n",
    "    tf_var_to_torch_var['width_scores/hidden_weights_0'] = 'span_width_mlp.fc_layers.0.weight'\n",
    "    tf_var_to_torch_var['width_scores/hidden_bias_0'] = 'span_width_mlp.fc_layers.0.bias'\n",
    "    tf_var_to_torch_var['width_scores/output_weights'] = 'span_width_mlp.fc_layers.1.weight'\n",
    "    tf_var_to_torch_var['width_scores/output_bias'] = 'span_width_mlp.fc_layers.1.bias'\n",
    "\n",
    "    tf_var_to_torch_var['span_width_embeddings'] = 'span_width_embeddings.weight'\n",
    "    tf_var_to_torch_var['span_width_prior_embeddings'] = 'span_width_prior_embeddings.weight'\n",
    "\n",
    "    for tf_var, torch_var in tf_var_to_torch_var.items():\n",
    "        numpy_mat = torch.from_numpy(tf.train.load_variable(tf_checkpoint, tf_var))\n",
    "        if ment_emb == 'endpoint' and tf_var == 'mention_scores/hidden_weights_0':\n",
    "            if model_size == 'base':\n",
    "                cutoff = 2 * 768 + 20\n",
    "            else:\n",
    "                cutoff = 2 * 1024 + 20\n",
    "            print(tf_var, cutoff)\n",
    "            numpy_mat = numpy_mat[:cutoff, :]\n",
    "        if 'weights' in tf_var:\n",
    "            numpy_mat = np.transpose(numpy_mat)\n",
    "            print(torch_var, numpy_mat.shape)\n",
    "\n",
    "        model_state_dict[torch_var] = numpy_mat\n",
    "            \n",
    "\n",
    "    torch.save(model_state_dict, pytorch_dump_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coref] *",
   "language": "python",
   "name": "conda-env-coref-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
