{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code.coref_utils.conll import evaluate_conll\n",
    "from code.coref_utils.utils import get_mention_to_cluster\n",
    "from code.coref_utils.metrics import CorefEvaluator\n",
    "from os import path\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data.append(json.loads(line.strip()))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/shtoshni/Research/litbank_coref/models/ontonotes_logs/ontonotes_unbounded.test.jsonl', '/home/shtoshni/Research/litbank_coref/models/ontonotes_logs/ontonotes_learned_20.test.jsonl', '/home/shtoshni/Research/litbank_coref/models/ontonotes_logs/ontonotes_learned_10.test.jsonl', '/home/shtoshni/Research/litbank_coref/models/ontonotes_logs/ontonotes_lru_10.test.jsonl']\n"
     ]
    }
   ],
   "source": [
    "ontonotes_log_dir=\"/home/shtoshni/Research/litbank_coref/models/ontonotes_logs\"\n",
    "conll_dir = \"/home/shtoshni/Research/litbank_coref/data/ontonotes/conll\"\n",
    "conll_scorer = \"/home/shtoshni/Research/litbank_coref/resources/reference-coreference-scorers/scorer.pl\"\n",
    "\n",
    "split = 'test'\n",
    "if split == 'test':\n",
    "    ontonotes_files = glob.glob(path.join(ontonotes_log_dir, \"*test.jsonl\"))\n",
    "else:\n",
    "    ontonotes_files = glob.glob(path.join(ontonotes_log_dir, \"*.jsonl\"))\n",
    "print(ontonotes_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_file_to_model(log_file):\n",
    "    model_name = path.basename(log_file).split(\".\")[0]\n",
    "#     print(model_name)\n",
    "    return model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-13 00:41:36,972 - ontonotes_unbounded (CoNLL) F-score : 77.4, MUC: 82.1 85.4 83.7, Bcub:  73.8 78.3 76.0, CEAFE:  72.2 72.6 72.4\n",
      "2020-08-13 00:41:40,905 - ontonotes_learned_20 (CoNLL) F-score : 77.3, MUC: 83.3 84.4 83.8, Bcub:  75.2 76.9 76.0, CEAFE:  73.1 71.1 72.1\n",
      "2020-08-13 00:41:44,936 - ontonotes_learned_10 (CoNLL) F-score : 76.2, MUC: 83.9 82.2 83.0, Bcub:  76.2 73.8 75.0, CEAFE:  72.1 69.4 70.7\n",
      "2020-08-13 00:41:48,936 - ontonotes_lru_10 (CoNLL) F-score : 75.0, MUC: 83.6 80.8 82.2, Bcub:  76.3 71.1 73.6, CEAFE:  69.3 68.8 69.0\n"
     ]
    }
   ],
   "source": [
    "for log_file in ontonotes_files:\n",
    "    model_name = log_file_to_model(log_file)\n",
    "    data = load_jsonl(log_file)\n",
    "    coref_predictions, subtoken_maps = {}, {}\n",
    "    for example in data:\n",
    "        predicted_clusters, mention_to_predicted =\\\n",
    "            get_mention_to_cluster(example[\"predicted_clusters\"], threshold=2)\n",
    "        gold_clusters, mention_to_gold =\\\n",
    "            get_mention_to_cluster(example[\"clusters\"], threshold=2)\n",
    "        \n",
    "        coref_predictions[example[\"doc_key\"]] = predicted_clusters\n",
    "        subtoken_maps[example[\"doc_key\"]] = example[\"subtoken_map\"]\n",
    "        \n",
    "    split='test'\n",
    "    gold_path = path.join(conll_dir, f'{split}.conll')\n",
    "    prediction_file = path.join(ontonotes_log_dir, f'{model_name}.conll')\n",
    "    if split == 'test':\n",
    "        prediction_file = path.join(ontonotes_log_dir, f'{model_name}.{split}.conll')\n",
    "#     print(prediction_file)\n",
    "#     print(coref_predictions.keys())\n",
    "    conll_results = evaluate_conll(\n",
    "        conll_scorer, gold_path, coref_predictions, subtoken_maps, prediction_file, all_metrics=True)\n",
    "    average_f1 = sum(results[\"f\"] for results in conll_results.values()) / len(conll_results)\n",
    "    logging.info(\"%s (CoNLL) F-score : %.1f, MUC: %.1f %.1f %.1f, Bcub:  %.1f %.1f %.1f, CEAFE:  %.1f %.1f %.1f\"\n",
    "                 % (model_name, average_f1, \n",
    "                    conll_results[\"muc\"][\"p\"], conll_results[\"muc\"][\"r\"], conll_results[\"muc\"][\"f\"], \n",
    "                    conll_results['bcub'][\"p\"], conll_results['bcub'][\"r\"], conll_results['bcub'][\"f\"],\n",
    "                    conll_results['ceafe'][\"p\"], conll_results['ceafe'][\"r\"], conll_results['ceafe'][\"f\"]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coref] *",
   "language": "python",
   "name": "conda-env-coref-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
