{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict, OrderedDict\n",
    "from os import path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            data.append(json.loads(line.strip()))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mention_to_cluster(clusters):\n",
    "    mention_to_cluster = {}\n",
    "    for cluster_idx, cluster in enumerate(clusters):\n",
    "        for mention in cluster:\n",
    "            mention_to_cluster[tuple(mention)] = cluster_idx\n",
    "    return mention_to_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_mentions(clusters):\n",
    "    \"\"\"Order all the mentions in the doc w.r.t. span_start and in case of ties span_end.\"\"\"\n",
    "    all_mentions = []\n",
    "    for cluster in clusters:\n",
    "        all_mentions.extend(cluster)\n",
    "    \n",
    "    # Span start is the main criteria, and span end is used to break ties\n",
    "    all_mentions = sorted(all_mentions, key=lambda x: x[0] + 1e-5 * x[1])\n",
    "    return all_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actions(clusters, num_cells=5):    \n",
    "    # Useful data structures\n",
    "    mention_to_cluster = get_mention_to_cluster(clusters)\n",
    "    ordered_mentions = get_ordered_mentions(clusters)\n",
    "    \n",
    "    actions = []\n",
    "    cell_to_cluster = {}\n",
    "    cell_to_last_used = [0 for cell in range(num_cells)]  # Initialize last usage of cell\n",
    "    cluster_to_cell = {}\n",
    "    # Initialize with all the mentions\n",
    "    cluster_to_rem_mentions = [len(cluster) for cluster in clusters]\n",
    "    \n",
    "    for mention in ordered_mentions:\n",
    "        used_cell_idx = None\n",
    "        mention_cluster = mention_to_cluster[tuple(mention)]\n",
    "        if mention_cluster in cluster_to_cell:\n",
    "            # Cluster is already being tracked\n",
    "            actions.append((cluster_to_cell[mention_cluster], 'c'))\n",
    "            # Update when the cell was last used\n",
    "            used_cell_idx = cluster_to_cell[mention_cluster]            \n",
    "        else:\n",
    "            # Cluster is not being tracked\n",
    "            # Find the cell with the least regret that we can overwrite to\n",
    "            # If the regret is non-positive i.e. we would be missing out on >= mentions\n",
    "            # of a cluster being currently tracked than the new mention cluster then we \n",
    "            # don't perform overwrite.\n",
    "            cur_rem_mentions = cluster_to_rem_mentions[mention_cluster]              \n",
    "            cell_info = []\n",
    "            for cell_idx in range(num_cells):\n",
    "                if cell_idx in cell_to_cluster:\n",
    "                    # The cell is actually in use\n",
    "                    cell_cluster = cell_to_cluster[cell_idx]\n",
    "                    cell_rem_mentions = cluster_to_rem_mentions[cell_cluster]\n",
    "                else:\n",
    "                    # The cell is not in use\n",
    "                    cell_rem_mentions = -1\n",
    "                                        \n",
    "                cell_info.append((cell_rem_mentions, cell_to_last_used[cell_idx], cell_idx))\n",
    "            \n",
    "            # Sort the cells primarily by the number of remaining mentions\n",
    "            # If the remaining mentions are tied, then compare the last used cell\n",
    "            cell_info = sorted(cell_info, key=lambda x: x[0] - 1e-5 * x[1])\n",
    "            min_remaining_mentions = cell_info[0][0]\n",
    "            \n",
    "            if cur_rem_mentions > min_remaining_mentions:\n",
    "                used_cell_idx = cell_info[0][2]  # Get the cell index\n",
    "            \n",
    "#             print(cell_info)\n",
    "            \n",
    "            if used_cell_idx is None:\n",
    "                # Ignore the mention\n",
    "                actions.append((-1, 'i'))\n",
    "            else:\n",
    "                # Overwrite\n",
    "                actions.append((used_cell_idx, 'o'))\n",
    "                \n",
    "                # Remove the cluster to cell reference for the replacement cell\n",
    "                # Only do this if the cell was tracking anything\n",
    "                if used_cell_idx in cell_to_cluster:\n",
    "                    del cluster_to_cell[cell_to_cluster[used_cell_idx]]\n",
    "                \n",
    "                # Add the mention to being tracked\n",
    "                cluster_to_cell[mention_cluster] = used_cell_idx\n",
    "                cell_to_cluster[used_cell_idx] = mention_cluster\n",
    "                \n",
    "#         print(actions[-1], used_cell_idx)\n",
    "\n",
    "        # Update the cell_to_last_used index\n",
    "        for cell_idx in range(num_cells):\n",
    "            cell_to_last_used[cell_idx] += 1\n",
    "        if used_cell_idx is not None:\n",
    "            cell_to_last_used[used_cell_idx] = 0\n",
    "#             print(cell_to_last_used)\n",
    "        \n",
    "        # Reduce the number of mentions remaining in the current cluster\n",
    "        cluster_to_rem_mentions[mention_cluster] -= 1\n",
    "            \n",
    "    return actions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_sequences_to_clusters(actions, mentions):\n",
    "    clusters = []\n",
    "    cell_to_clusters = {}\n",
    "    \n",
    "    for mention, (cell_idx, action_type) in zip(mentions, actions):\n",
    "        if action_type == 'i':\n",
    "            # Singleton\n",
    "            clusters.append([mention])\n",
    "        elif action_type == 'c':\n",
    "            cell_to_clusters[cell_idx].append(mention)\n",
    "        else:\n",
    "            # Overwrite\n",
    "            if cell_idx in cell_to_clusters:\n",
    "                # Remove the old cluster and initialize the new\n",
    "                clusters.append(cell_to_clusters[cell_idx])\n",
    "            cell_to_clusters[cell_idx] = [mention]\n",
    "    \n",
    "    for cell_idx, cluster in cell_to_clusters.items():\n",
    "        clusters.append(cluster)\n",
    "        \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_clusters_are_same_or_not(cluster_list1, cluster_list2):\n",
    "    def get_ordered_cluster(cluster_list):\n",
    "        first_mention_to_whole_cluster = {}\n",
    "        for cluster in cluster_list:\n",
    "            sorted_mentions = sorted(cluster, key=lambda x: x[0] + x[1] * 1e-5)\n",
    "            first_mention_to_whole_cluster[tuple(sorted_mentions[0])] = sorted_mentions\n",
    "        return first_mention_to_whole_cluster\n",
    "    \n",
    "    ord_cluster1 = get_ordered_cluster(cluster_list1)\n",
    "    ord_cluster2 = get_ordered_cluster(cluster_list2)\n",
    "    \n",
    "    for mention, cluster in ord_cluster1.items():\n",
    "        if mention not in ord_cluster2:\n",
    "            return False\n",
    "        else:\n",
    "            if ord_cluster1[mention] != ord_cluster2[mention]:\n",
    "                return False\n",
    "            \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/home/shtoshni/Research/litbank_coref/data/segmentation\"\n",
    "output_dir = \"/home/shtoshni/Research/litbank_coref/data/autoregressive\"\n",
    "\n",
    "for num_cells in [2, 5, 10, 15, 20]:\n",
    "    output_file = path.join(output_dir, \"all.cell_{}.{}.jsonlines\".format(num_cells, max_segment_len))\n",
    "    with open(output_file, 'w') as f:\n",
    "        for doc in litbank_data:\n",
    "            clusters = doc[\"clusters\"]\n",
    "            actions = get_actions(clusters, num_cells=num_cells)\n",
    "            ord_mentions = get_ordered_mentions(clusters)\n",
    "            pred_clusters = action_sequences_to_clusters(actions, ord_mentions)\n",
    "            mention_to_cluster = get_mention_to_cluster(clusters)\n",
    "            \n",
    "            doc['actions'] = actions\n",
    "            doc['oracle_clusters'] = pred_clusters\n",
    "            doc['ord_mentions'] = ord_mentions\n",
    "            doc['cluster_ids'] = [mention_to_cluster[tuple(mention)] for mention in ord_mentions]\n",
    "            f.write(json.dumps(doc) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_cells in [20]:\n",
    "    for doc in litbank_data:\n",
    "        clusters = doc[\"clusters\"]\n",
    "        actions = get_actions(clusters, num_cells=num_cells)\n",
    "        ord_mentions = get_ordered_mentions(clusters)\n",
    "        pred_clusters = action_sequences_to_clusters(actions, ord_mentions)\n",
    "        mention_to_cluster = get_mention_to_cluster(clusters)\n",
    "        \n",
    "        if not check_clusters_are_same_or_not(clusters, pred_clusters):\n",
    "            print(doc[\"doc_key\"])\n",
    "        doc['actions'] = actions\n",
    "        doc['oracle_clusters'] = pred_clusters\n",
    "        doc['ord_mentions'] = ord_mentions\n",
    "        doc['cluster_ids'] = [mention_to_cluster[tuple(mention)] for mention in ord_mentions]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:coref] *",
   "language": "python",
   "name": "conda-env-coref-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
